 
## ðŸ“‚ Repository Structure

digital-phenotyping-data/
```text
â”‚
â”œâ”€â”€ data/ # Sample anonymized data files
â”‚ â”œâ”€â”€ accelerometer/
â”‚ â”œâ”€â”€ gps/
â”‚ â””â”€â”€ screen_usage/
â”‚
â”œâ”€â”€ scripts/ # Scripts for data collection and preprocessing
â”‚ â”œâ”€â”€ mobile_collection/
â”‚ â””â”€â”€ preprocessing/
â”‚
â”œâ”€â”€ docs/ # Documentation and protocols
â”‚ â””â”€â”€ consent_templates/
â”‚
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## Table of Contents
* [Activity Detection](#activity)
* 

## Datasets
### Activity Detection
* [Joint Learning of Invariant](https://github.com/suhaslohit/TTN) - Temporal Transformer Network (TTN) is proposed as a hybrid model-based and data-driven approach to learn warping functions that not just reduce intra-class variability, but also increase inter-class separation. [[data](https://github.com/suhaslohit/TTN)][[paper](http://openaccess.thecvf.com/content_CVPR_2019/html/Lohit_Temporal_Transformer_Networks_Joint_Learning_of_Invariant_and_Discriminative_Time_CVPR_2019_paper.html)][[code](https://github.com/suhaslohit/TTN)]
* [Human Activity Recognition](https://arxiv.org/abs/2104.08094) - A novel hybrid method for Human Activity Recognition that combines semi-supervised and federated learning. [[paper](https://arxiv.org/abs/2104.08094)][[data[30][49]]()][[code(Under request)](www.hayat.com)]
* [LSTM for Human Activity Recognition]() - Human Activity Recognition using TensorFlow on smartphone sensors dataset and an LSTM RNN. The dataset is used to classify the type of movement amongst six activity categories. [[code](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition)][[data](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/tree/master/data)]
* [CNN for Human Activity Recognition](https://github.com/aqibsaeed/Human-Activity-Recognition-using-CNN/tree/master) - Application of Convolutional Neural network for Human Activity Recognition in TensorFlow. [[data](https://www.cis.fordham.edu/wisdm/dataset.php)][[code](https://github.com/aqibsaeed/Human-Activity-Recognition-using-CNN/blob/master/Activity%20Detection.ipynb)]
* [Human Activity Recognition](https://www.utwente.nl/en/eemcs/ps/) - The Complex human activity recognition using smartphone and wrist-worn motion sensors.[[data](https://www.utwente.nl/en/eemcs/ps/)][[paper](https://www.mdpi.com/1424-8220/16/4/426)][[code](www.code.com)]
* [Classification of Human Activities](https://github.com/ma-shamshiri/Human-Activity-Recognition/tree/main) - Comparison of various classifiers, including Decision Tree, K-Nearest neighbours, Random Forest, SVM, and CNN on two different preprocessed datasets. [[data](https://github.com/ma-shamshiri/Human-Activity-Recognition/tree/main/code/data)][[code](https://github.com/ma-shamshiri/Human-Activity-Recognition/tree/main/code)].
* [Human Activity Recognition](https://github.com/ani8897/Human-Activity-Recognition/tree/master) - Classifying the physical activities performed by a user based on accelerometer and gyroscope sensor data collected by a smartphone in the user's pockets. The activities classified are: standing, sitting, stairsup, stairsdown, walking and cycling. [[data](https://archive.ics.uci.edu/ml/datasets/Heterogeneity+Activity+Recognition)][[code](https://github.com/ani8897/Human-Activity-Recognition/tree/master)].
* [Human Activity Recognition using CNN in Keras](https://github.com/Shahnawax/HAR-CNN-Keras) - A 3D accelerometer sensor data is used to train a simple Convolutional Neural Network (CNN) based Human Activity Recognition (HAR) system. [[data[(http://www.cis.fordham.edu/wisdm/dataset.php)][[code](https://github.com/Shahnawax/HAR-CNN-Keras)].
* [Human Activity Recognition from smartphone signals](https://github.com/servomac/Human-Activity-Recognition) - Human activities are predicted using a LSTM network trained on sensor signals collected from a smartphone. [[data](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)][[code](https://github.com/servomac/Human-Activity-Recognition)].
* [Skeleton-Based Activity Recognition](https://link.springer.com/chapter/10.1007/978-3-030-68796-0_50) - Spatial Temporal Transformer Network for Skeleton-Based Activity Recognition. [[data](https://drive.google.com/drive/folders/1SPQ6FmFsjGg3f59uCWfdUWI-5HJM_YhZ)][[code](https://github.com/Chiaraplizz/ST-TR)].
* [Human Activity Recognition](https://dl.acm.org/doi/10.1145/2499621) - The use of MATLAB toolbox for Human Activity Recognition. [[data](https://github.com/andreas-bulling/ActRecTut/tree/master/Data)][[code](https://github.com/andreas-bulling/ActRecTut)].
* [Human Activity Recognition using Signal Processing](https://github.com/anas337/Human-Activity-Recognition-Using-Smartphones.github.io) - [[data](https://github.com/anas337/Human-Activity-Recognition-Using-Smartphones.github.io/tree/master/Data)][[code](https://github.com/anas337/Human-Activity-Recognition-Using-Smartphones.github.io)].
* [Awesome Human Activity Recognition](https://github.com/haoranD/Awesome-Human-Activity-Recognition) - This is an up-to-date and curated list of awesome IMU-based human activity recognition papers, methods and resources.
* 
* 
* [Human Activity Recognition using Smartphones](https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones) - A freely available data recorded as a set of ADL in a sensor rich environment using 72 environmental and body sensors. [[data](https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones)][[paper](https://www.esann.org/sites/default/files/proceedings/legacy/es2013-84.pdf)]
* [Human Pedestrian Activity Recognition](http://hub.hasc.jp/) - The authors collected indoor pedestrian sensing data of 107 people with a balance of gender and age. [[data](http://hub.hasc.jp/)] [[paper](https://dl.acm.org/doi/abs/10.1145/2968219.2968277)]
* [Daily life activities](https://www.mad.tf.fau.de/research/activitynet) - This is a hierarchical, multi-sensor based classification. [[data](https://www.mad.tf.fau.de/research/activitynet)][[paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0075196)]
* [Automatic pattern segmentation from accelerometry data](https://github.com/martakarass/adept-manuscript) - A dataset collected at various body locations and is invariant to the direction of accelerometrer axes relative to body orientation involving 32 study participants wearing accelerometers on the wrist, hip, and both ankles. [[paper](https://academic.oup.com/biostatistics/article/22/2/331/5572661)][[data](https://github.com/martakarass/adept-manuscript)]
* [Motion Sense](https://github.com/mmalekzadeh/motion-sense/tree/master) - A time-series dataset generated by accelerometer and gyroscope sensors for human activity and attribute recognition. [[data](https://github.com/mmalekzadeh/motion-sense/tree/master)][[paper](https://dl.acm.org/doi/pdf/10.1145/3302505.3310068)]
* [Fusion of smartphone motion sensors for activity recognition](https://www.utwente.nl/en/eemcs/ps/) - Smartphone sensors collected data for seven physical activities (walking, running, sitting, standing, jogging, biking, walking upstrairs and walking downstairs) from ten participants. [[data](https://www.utwente.nl/en/eemcs/ps/)][[paper](https://www.mdpi.com/1424-8220/14/6/10146?ref=https://githubhelp.com)]
* The dataset includes more than 60,000 video recorded steps for the evaluation of pedometer algorithm to be evaluated across multiple sensor locations (wrist, hip, and ankle). The dataset is collected from thirty participants (15 males & 15 females). [[data]()][[paper](https://ieeexplore.ieee.org/abstract/document/8217769)] [To be removed]
* [Position-Aware Activity Recognition](http://sensor.informatik.uni-mannheim.de/) - The data is collected from 15 participants for 8 common activities from 7 wearable devices in different positions. [[data](http://sensor.informatik.uni-mannheim.de/)][[paper](https://ieeexplore.ieee.org/abstract/document/7456521)]
* [UniMiB SHAR](http://www.sal.disco.unimib.it/technologies/unimib-shar/) - A dataset for human activity recognition using acceleration data from smartphones [[data](http://www.sal.disco.unimib.it/technologies/unimib-shar/)][[paper](https://www.mdpi.com/2076-3417/7/10/1101)]
* 

### Phenotyping
* [Smartphone-based Digital Phenotyping]() - Digital Phenotyping [[code](https://github.com/bhagyas731/Smartphone-based-Digital-Phenotyping/blob/main/Smartphone-based%20Digital%20Phenotyping.ipynb)][[data](https://github.com/bhagyas731/Smartphone-based-Digital-Phenotyping)].
* [Digital Phenotyping]() - Digital Phenotyping using accelerometer, communication_log, gps imputation 2D and gps imputation sphere. [[code](https://github.com/GreysonL/DigitalPhenotyping/tree/master)]][[No data]()]
* 


### Mental Health Monitoring
* [Detection of Autism](https://www.nature.com/articles/s41591-023-02574-3) - The dataset contains data collected and deposited in the National Institute of Mental Health National Data Archive (NDA). [[data](https://nda.nih.gov/)][[code](https://github.com/samperochon/Perochon_et_al_Nature_Medicine_2023)].
* 


### Sleep Analysis
* [Sleep Quality identification](https://figshare.com/ndownloader/files/14578382) - Data collected to identify sleep quality [[paper](https://www.nature.com/articles/s42003-019-0605-1)][[data](https://figshare.com/ndownloader/files/14578382)]
* 









